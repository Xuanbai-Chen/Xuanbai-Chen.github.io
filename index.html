<!DOCTYPE HTML>
<html lang="en" xmlns="http://www.w3.org/1999/html">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Xuanbai Chen</title>
  <meta name="author" content="Xuanbai Chen">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>


<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">


        <!--bio paragraph-->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Xuanbai Chen</name>
              </p>
              <p>Xuanbai Chen is an Applied Scientist in <a href="https://aws.amazon.com/rekognition/">AWS AI Rekognition</a> team, and is currently
                working on face recognition and trustworthy AI.
              </p>
              <p>
                Prior to AWS, he obtained my <a href="https://www.ri.cmu.edu/education/academic-programs/master-of-science-computer-vision/">Master of Science in Computer Vision (MSCV)</a> Degree
                in the <a href="https://www.ri.cmu.edu/">Robotics Institute</a>, <a href="https://www.cs.cmu.edu/">School of Computer Science</a>, <a href="https://www.cmu.edu/">Carnegie Mellon University</a>.
                He worked with <a href="https://www.cs.cmu.edu/~ftorre/">Prof. Fernando De la Torre</a> on Fairness for Generation Model and 3D Face modeling.
                He obtained my Bachelor of Engineering in Computer Science Degree in <a href="https://cc.nankai.edu.cn/">College of Computer Science</a>, <a href="https://en.nankai.edu.cn/">Nankai University</a>, working on Video Summarization.
              </p>
              <p style="text-align:center">
                <a href="mailto:xuanbaic98@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/xuanbaic/">LinkedIn</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=UZ8IbowAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.overleaf.com/read/swvmmvvqfhqy">CV</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/xuanbaic.jpg"><img style="width:80%;max-width:80%" alt="profile photo" src="images/xuanbaic.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>




        <!--News-->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>News</heading>
            <p>
              <li style="margin: 5px;" >
                  <b>2023-10:</b> ITI-GEN has entered the <b>Best Paper Finalist</b> (17 of 2161, <b>Top 0.7%</b>) for ICCV 2023.
              </li>
              <li style="margin: 5px;" >
                  <b>2023-08:</b> Our <a href="https://czhang0528.github.io/iti-gen"> ITI-GEN</a> has been accepted by <a href="https://iccv2023.thecvf.com/">ICCV 2023</a> as an <b>Oral</b> paper.
              </li>
              <li style="margin: 5px;" >
                <b>2023-07:</b> I joined <a href="https://aws.amazon.com/rekognition/">AWS AI Rekognition</a> team as an Applied Scientist!
              </li>
<!--              <li style="margin: 5px;" >-->
<!--                <b>2021-09:</b> <a href="https://dynamicvit.ivg-research.xyz"> DynamicViT</a> is accepted to <a href="https://neurips.cc/Conferences/2021">NeurIPS 2021</a>.-->
<!--              </li>-->
<!--              <li style="margin: 5px;" >-->
<!--                <b>2021-07:</b> Two papers are accepted to <a href="https://iccv2021.thecvf.com">ICCV 2021</a>.-->
<!--              </li>-->
<!--              <li style="margin: 5px;" >-->
<!--                <b>2020-12:</b> One paper on image classification is accepted to <a href="https://aaai.org/Conferences/AAAI-21/">AAAI 2021</a>.-->
<!--              </li>-->
<!--              <li style="margin: 5px;" >-->
<!--                <b>2020-07:</b> One paper on knowledge distillation is accepted by <a href="https://eccv2020.eu/">ECCV 2020</a>.-->
<!--              </li>-->
            </p>
          </td>
          </tr>
        </tbody></table>



        <!--publications-->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading> (* indicates equal contribution)
            </td>
          </tr>
        </tbody></table>

        <!--   iti-gen     -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td align="center" valign="middle">&nbsp;&nbsp;&nbsp;<img src="images/iti_gen/teaser.png", width="200">&nbsp;&nbsp;&nbsp;&nbsp;
			</td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_ITI-GEN_Inclusive_Text-to-Image_Generation_ICCV_2023_paper.html">
                <span class="papertitle">ITI-GEN: Inclusive Text-to-Image Generation</span>
              </a>
              <br>
              <a href="https://czhang0528.github.io/">Cheng Zhang</a>,
              <strong>Xuanbai Chen</strong>,
              <a href="https://www.linkedin.com/in/siqi-chai/">Siqi Chai</a>,
              <a href="https://scholar.google.com/citations?hl=en&user=WFKit_4AAAAJ&view_op=list_works&sortby=pubdate">Chen Henry Wu</a>,
              <a href="https://www.linkedin.com/in/dmitry-lagun-738b1221/">Dmitry Lagun</a>,
              <a href="https://thabobeeler.com/">Thabo Beeler</a>,
              <a href="https://www.cs.cmu.edu/~ftorre/">Fernando De la Torre</a>
              <br>
              <em>ICCV</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation, Best Paper Finalist, Top 0.7%)</strong></font>
              <br>
              <a href="https://czhang0528.github.io/iti-gen">project page</a>
              /
              <a href="https://arxiv.org/abs/2309.05569">arXiv</a>
              /
              <a href="https://github.com/humansensinglab/ITI-GEN">code</a>
              /
              <a href="https://drive.google.com/drive/folders/1_vwgrcSq6DKm5FegICwQ9MwCA63SkRcr?usp=sharing">data</a>
              /
              <a href="images/iti_gen/iti-gen_poster.pdf">poster</a>
              <p></p>
              <p>
              Debias the text-to-image generation model and implement the inclusiveness.
              </p>
            </td>
          </tr>
        </tbody></table>



        <!--   3d face cam     -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td align="center" valign="middle">&nbsp;&nbsp;&nbsp;<img src="images/3dfacecam/3dfacecam.gif", width="200">&nbsp;&nbsp;&nbsp;&nbsp;
			</td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content/WACV2023/html/Taherkhani_Controllable_3D_Generative_Adversarial_Face_Model_via_Disentangling_Shape_and_WACV_2023_paper.html">
                <span class="papertitle">Controllable 3D Generative Adversarial Face Model via Disentangling Shape and Appearance</span>
              </a>
              <br>
              <a href="https://ulteraa.github.io/Fariborz.github.io/">Fariborz Taherkhani</a>,
              <a href="https://aashishrai3799.github.io/">Aashish Rai</a>,
              <a href="https://zerg-overmind.github.io/">Quankai Gao</a>,
              <a href="https://shaunak99.github.io/profilev2/">Shaunak Srivastava</a>,
              <strong>Xuanbai Chen</strong>,
              <a href="https://www.cs.cmu.edu/~ftorre/">Fernando De la Torre</a>,
              Steven Song,
              <a href="https://aayushp.github.io/">Aayush Prakash</a>,
              Daeil Kim
              <br>
              <em>WACV</em>, 2023
              <br>
              <a href="https://aashishrai3799.github.io/3DFaceCAM/">project page</a>
              /
              <a href="https://arxiv.org/abs/2208.14263">arXiv</a>
              /
              <a href="https://github.com/aashishrai3799/3DFaceCAM/tree/main#controllable-3d-generative-adversarial-face-model-via-disentangling-shape-and-appearance">code</a>
              /
              <a href="https://drive.google.com/file/d/1PqIN4Rzp4vapWs2pUegUEoMhg4lM2Smy/view">video</a>
              <p></p>
              <p>
              A new 3D face generative model that can decouple identity and expression and provides granular control over expressions.
              </p>
            </td>
          </tr>
        </tbody></table>



        <!--   KAMV    -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td align="center" valign="middle">&nbsp;&nbsp;&nbsp;<img src="images/kamv/figure.png", width="140">&nbsp;&nbsp;&nbsp;&nbsp;
			</td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://dl.acm.org/doi/abs/10.1145/3503161.3548089">
                <span class="papertitle">A Knowledge Augmented and Multimodal-Based Framework for Video Summarization</span>
              </a>
              <br>
              <a href="https://www.semanticscholar.org/author/Jiehang-Xie/147178951">Jiehang Xie*</a>,
              <strong>Xuanbai Chen*</strong>,
              <a href="https://www.shaopinglu.net/">Shao-Ping Lu</a>,
              <a href="https://dblp.org/pid/14/1508.html">Yulu Yang</a>
              <br>
              <em>ACMMM</em>, 2022
              <br>
              <a href="https://dl.acm.org/doi/abs/10.1145/3503161.3548089">project page</a>
              /
              <a href="https://dl.acm.org/doi/pdf/10.1145/3503161.3548089">pdf</a>
              /
              <a href="https://dl.acm.org/action/downloadSupplement?doi=10.1145%2F3503161.3548089&file=MM22-1409.mp4">video</a>
              <p></p>
              <p>
              Propose a knowledge augmented and multimodal-based video summarization method, by considering multichannel information and using the impact of external knowledge.
              </p>
            </td>
          </tr>
        </tbody></table>




        <!-- MANVS  -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td align="center" valign="middle">&nbsp;&nbsp;&nbsp;<img src="images/manvs/figure.png", width="150">&nbsp;&nbsp;&nbsp;&nbsp;
			</td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/9797228">
                <span class="papertitle">Multimodal-based and Aesthetic-guided Narrative Video Summarization</span>
              </a>
              <br>
              <a href="https://www.semanticscholar.org/author/Jiehang-Xie/147178951">Jiehang Xie</a>,
              <strong>Xuanbai Chen</strong>,
              <a href="https://tianyi-zhang-tz.github.io/Tianyi-Zhang-TZ/">Tianyi Zhang</a>,
              Yixuan Zhang,
              <a href="https://www.shaopinglu.net/">Shao-Ping Lu</a>,
              <a href="https://www.pablocesar.me/">Pablo Cesar</a>,
              <a href="https://dblp.org/pid/14/1508.html">Yulu Yang</a>
              <br>
              <em>IEEE TMM</em>, 2022
              <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/9797228">project page</a>
              /
              <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9797228">pdf</a>
              <p></p>
              <p>
              Introduce a multimodal-based and aesthetic-guided narrative video summarization method, by leveraging multimodal information through specified key shots selection, subtitle summarization, and highlight extraction components.
              </p>
            </td>
          </tr>
        </tbody></table>




        <!-- CycleEmotionGAN++  -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td align="center" valign="middle">&nbsp;&nbsp;&nbsp;<img src="images/cycleemotiongan/figure.png", width="200">&nbsp;&nbsp;&nbsp;&nbsp;
			</td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/9385998">
                <span class="papertitle">Emotional Semantics-Preserved and Feature-Aligned CycleGAN for Visual Emotion Adaptation</span>
              </a>
              <br>
              <a href="https://sites.google.com/view/schzhao">Sicheng Zhao*</a>,
              <strong>Xuanbai Chen*</strong>,
              <a href="http://people.eecs.berkeley.edu/~xyyue/">Xiangyu Yue</a>,
              <a href="https://clin1223.github.io/">Chuang Lin</a>,
              <a href="https://scholar.google.com/citations?user=ck6i0ucAAAAJ&hl=en">Pengfei Xu</a>,
              Ravi Krishna,
              <a href="https://cv.nankai.edu.cn/">Jufeng Yang</a>,
              <a href="https://scholar.google.com/citations?user=B7F3yt4AAAAJ&hl=en">Ding Guiguang</a>,
              <a href="https://scholar.google.com/citations?user=AhgjQ2QAAAAJ&hl=en">Alberto Sangiovanni Vincentelli</a>,
              <a href="https://scholar.google.com/citations?user=ID9QePIAAAAJ&hl=en">Kurt Keutzer</a>
              <br>
              <em>IEEE TCYB</em>, 2021
              <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/9385998">project page</a>
              /
              <a href="https://arxiv.org/abs/2011.12470">arxiv</a>
              <p></p>
              <p>
                Design a novel end-to-end cycle-consistent adversarial model, to focus on UDA in visual emotion analysis for both emotion distribution learning and dominant emotion classification.
              </p>
            </td>
          </tr>
        </tbody></table>



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Education and Experiences</heading>
                </td>
            </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
            <!-- AWS -->
            <tr>
                <td style="padding:20px;width:25%;vertical-align:top" align="center">
                    <img src="images/experiences/aws.jpeg" style="horiz-align: right" width="150px">
                </td>
                <td width="75%" valign="top">
                    <p><a href="https://aws.amazon.com/rekognition/"><strong style="font-size: 18px">AWS AI Rekognition</strong></a>, <strong style="font-size: 18px">Jul. 2023 - Present</strong></p>
                    <p>Applied Scientist</p>
                </td>
            </tr>
            <!-- CMU -->
            <tr>
                <td style="padding:20px;width:25%;vertical-align:top" align="center">
                    <img src="images/experiences/cmu.png" style="horiz-align: right" width="150px">
                </td>
                <td width="75%" valign="top">
                    <p><a href="https://www.cmu.edu/"><strong style="font-size: 18px">Carnegie Mellon University</strong></a>, <strong style="font-size: 18px">Jan. 2022 - May. 2023</strong></p>
                    <p>Master of Science in Computer Vision</p>
                </td>
            </tr>
            <!-- AWS -->
            <tr>
                <td style="padding:20px;width:25%;vertical-align:top" align="center">
                    <img src="images/experiences/aws.jpeg" style="horiz-align: right" width="150px">
                </td>
                <td width="75%" valign="top">
                    <p><a href="https://aws.amazon.com/rekognition/"><strong style="font-size: 18px">AWS AI Rekognition</strong></a>, <strong style="font-size: 18px">May. 2022 - Aug. 2022</strong></p>
                    <p>Applied Scientist Intern</p>
                </td>
            </tr>
            <!-- Sensetime -->
            <tr>
                <td style="padding:20px;width:25%;vertical-align:top" align="center">
                    <img src="images/experiences/sensetime.jpeg" style="horiz-align: right" width="150px">
                </td>
                <td width="75%" valign="top">
                    <p><a href="https://www.sensetime.com/en"><strong style="font-size: 18px">Sensetime</strong></a>, <strong style="font-size: 18px">Aug. 2021 - Dec. 2021</strong></p>
                    <p>Research Engineer Intern</p>
                </td>
            </tr>
            <!-- UCB -->
            <tr>
                <td style="padding:20px;width:25%;vertical-align:top" align="center">
                    <img src="images/experiences/berkeley.png" style="horiz-align: right" width="150px">
                </td>
                <td width="75%" valign="top">
                    <p><a href="https://www.berkeley.edu/"><strong style="font-size: 18px">University of California, Berkeley</strong></a>, <strong style="font-size: 18px">Jan. 2020 - May. 2020</strong></p>
                    <p>Exchange Program</p>
                </td>
            </tr>
            <!-- Nankai -->
            <tr>
                <td style="width:25%;vertical-align:top;horiz-align: right" align="center">
                    <img src="images/experiences/nankai.png" style="horiz-align: right" width="150px">
                </td>
                <td width="75%" style="vertical-align:top">
                    <p><a href="https://en.nankai.edu.cn/"><strong style="font-size: 18px">Nankai University</strong></a>, <strong style="font-size: 18px">Sep. 2017 - Jun. 2021</strong></p>
                    <p>Bachelor of Engineering in Computer Science</p>
                </td>
            </tr>
            <!--     hhhh       -->
            </tbody>
        </table>



        <!--academic service-->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Academic Services</heading>
                <p>
                  <li style="margin: 5px;">
                    <b>Journal Reviewer:</b>  IEEE TCYB, TNSRE, KBS
                  </li>
                  <li style="margin: 5px;">
                    <b>Conference Reviewer:</b>  ACMMM 2023, CVPR 2024
                  </li>
                  <li style="margin: 5px;">
                    <b>Student Volunteer:</b>  ICCV 2023
                  </li>
                </p>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Miscellaneous</heading>
                <p align="justify">
                    The initial label for me is a sports fan and I love watching various sports games in my leisure time. My favorite players are LeBron James, Lionel Messi, Roger Federer for basketball, football, and tennis respectively.
                </p>
                <p align="justify">
                    Furthermore, I will also spend some time in watching popularization videos in different subjects to prevent me from being 'ignorant' in other fields.
                    <!-- Check my <a href="https://xuanbai-chen.github.io/">blogs</a> which show my perspective for different things.-->
                </p>
            </td>
          </tr>
        </tbody></table>

    </td></tr>
  </tbody></table>

    <p>
      <center>
          <div id="clustrmaps-widget" style="width:20%">
            <script type="text/javascript" id="mapmyvisitors" src="//mapmyvisitors.com/map.js?d=_4wnmcZthdDL7Y20ecaEP9y8aJ2WGqD1dpAjBwIP6uU&cl=ffffff&w=a"></script>
          </div>
          <br>&copy; Xuanbai Chen | Last updated: Nov 11, 2023 | Jon Barron's webpage template
      </center>
    </p>

  </body>
</html>