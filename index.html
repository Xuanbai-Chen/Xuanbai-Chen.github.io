<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Xuanbai Chen</title>
  <meta name="author" content="Xuanbai Chen">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>


<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">


        <!--bio paragraph-->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Xuanbai Chen</name>
              </p>
              <p>Xuanbai Chen is an Applied Scientist in <a href="https://aws.amazon.com/rekognition/">AWS AI Rekognition</a> team, and is currently
                working on face recognition and trustworthy AI.
              </p>
              <p>
                Prior to AWS, he obtained my <a href="https://www.ri.cmu.edu/education/academic-programs/master-of-science-computer-vision/">Master of Science in Computer Vision (MSCV)</a> Degree
                in the <a href="https://www.ri.cmu.edu/">Robotics Institute</a>, <a href="https://www.cs.cmu.edu/">School of Computer Science</a>, <a href="https://www.cmu.edu/">Carnegie Mellon University</a>.
                He worked with <a href="https://www.cs.cmu.edu/~ftorre/">Prof. Fernando De la Torre</a> on Fairness for Generation Model and 3D Face modeling.
                He obtained my Bachelor of Engineering in Computer Science Degree in <a href="https://cc.nankai.edu.cn/">College of Computer Science</a>, <a href="https://en.nankai.edu.cn/">Nankai University</a>, working on Video Summarization.
              </p>
              <p style="text-align:center">
                <a href="mailto:xuanbaic98@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/xuanbaic/">LinkedIn</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=UZ8IbowAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.overleaf.com/read/swvmmvvqfhqy">CV</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/xuanbaic.jpg"><img style="width:80%;max-width:80%" alt="profile photo" src="images/xuanbaic.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>News</heading>
            <p>
              <li style="margin: 5px;" >
                  <b>2023-08:</b> Our <a href="https://czhang0528.github.io/iti-gen"> ITI-GEN</a> has been accepted by <a href="https://iccv2023.thecvf.com/">ICCV 2023</a> as an <b>Oral</b> paper.
              </li>
              <li style="margin: 5px;" >
                <b>2023-07:</b> I joined AWS AI Rekognition team as an Applied Scientist!
              </li>
<!--              <li style="margin: 5px;" >-->
<!--                <b>2021-09:</b> <a href="https://dynamicvit.ivg-research.xyz"> DynamicViT</a> is accepted to <a href="https://neurips.cc/Conferences/2021">NeurIPS 2021</a>.-->
<!--              </li>-->
<!--              <li style="margin: 5px;" >-->
<!--                <b>2021-07:</b> Two papers are accepted to <a href="https://iccv2021.thecvf.com">ICCV 2021</a>.-->
<!--              </li>-->
<!--              <li style="margin: 5px;" >-->
<!--                <b>2020-12:</b> One paper on image classification is accepted to <a href="https://aaai.org/Conferences/AAAI-21/">AAAI 2021</a>.-->
<!--              </li>-->
<!--              <li style="margin: 5px;" >-->
<!--                <b>2020-07:</b> One paper on knowledge distillation is accepted by <a href="https://eccv2020.eu/">ECCV 2020</a>.-->
<!--              </li>-->
            </p>
          </td>
          </tr>
        </tbody></table>

<!--        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>-->
<!--            <tr>-->
<!--            <td style="padding:20px;width:100%;vertical-align:middle">-->
<!--              <heading>Publications</heading>-->
<!--              <p>-->
<!--                I'm interested in computer vision, machine learning, optimization, and image processing. Much of my research is about inferring the physical world (shape, motion, color, light, etc) from images. Representative papers are <span class="highlight">highlighted</span>.-->
<!--              </p>-->
<!--            </td>-->
<!--          </tr>-->
<!--        </tbody></table>-->



<!--        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>-->
<!--					-->
<!--          <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">-->
<!--            <td style="padding:20px;width:25%;vertical-align:middle">-->
<!--              <div class="one">-->
<!--                <div class="two" id='nerfsuper_image'><video  width=100% height=100% muted autoplay loop>-->
<!--                <source src="images/nerf_supervision.mp4" type="video/mp4">-->
<!--                Your browser does not support the video tag.-->
<!--                </video></div>-->
<!--                <img src='images/nerf_supervision.jpg' width="160">-->
<!--              </div>-->
<!--              <script type="text/javascript">-->
<!--                function nerfsuper_start() {-->
<!--                  document.getElementById('nerfsuper_image').style.opacity = "1";-->
<!--                }-->

<!--                function nerfsuper_stop() {-->
<!--                  document.getElementById('nerfsuper_image').style.opacity = "0";-->
<!--                }-->
<!--                nerfsuper_stop()-->
<!--              </script>-->
<!--            </td>-->
<!--            <td style="padding:20px;width:75%;vertical-align:middle">-->
<!--							<a href="http://yenchenlin.me/nerf-supervision/">-->
<!--                <papertitle>NeRF-Supervision: Learning Dense Object Descriptors from Neural Radiance Fields</papertitle>-->
<!--              </a>-->
<!--              <br>-->
<!--              <a href="https://yenchenlin.me/">Lin Yen-Chen</a>, -->
<!--              <a href="http://www.peteflorence.com/">Pete Florence</a>, -->
<!--              <strong>Jonathan T. Barron</strong>,  <br>-->
<!--              <a href="https://scholar.google.com/citations?user=_BPdgV0AAAAJ&hl=en">Tsung-Yi Lin</a>, -->
<!--              <a href="https://meche.mit.edu/people/faculty/ALBERTOR@MIT.EDU">Alberto Rodriguez</a>,-->
<!--              <a href="http://web.mit.edu/phillipi/">Phillip Isola</a>-->
<!--              <br>-->
<!--              <em>ICRA</em>, 2022  -->
<!--              <br>-->
<!--							<a href="http://yenchenlin.me/nerf-supervision/">project page</a> / -->
<!--							<a href="https://arxiv.org/abs/2203.01913">arXiv</a> / -->
<!--							<a href="https://www.youtube.com/watch?v=_zN-wVwPH1s">video</a> /-->
<!--							<a href="https://github.com/yenchenlin/nerf-supervision-public">code</a> / -->
<!--							<a href="https://colab.research.google.com/drive/13ISri5KD2XeEtsFs25hmZtKhxoDywB5y?usp=sharing">colab</a>				-->
<!--              <p></p>-->
<!--              <p>NeRF works better than RGB-D cameras or multi-view stereo when learning object descriptors.</p>-->
<!--            </td>-->
<!--          </tr>-->




<!--          <tr onmouseout="loss_stop()" onmouseover="loss_start()" bgcolor="#ffffd0">-->
<!--            <td style="padding:20px;width:25%;vertical-align:middle">-->
<!--              <div class="one">-->
<!--                <div class="two" id='loss_image'><img src='images/loss_after.png'></div>-->
<!--                <img src='images/loss_before.png'>-->
<!--              </div>-->
<!--              <script type="text/javascript">-->
<!--                function loss_start() {-->
<!--                  document.getElementById('loss_image').style.opacity = "1";-->
<!--                }-->

<!--                function loss_stop() {-->
<!--                  document.getElementById('loss_image').style.opacity = "0";-->
<!--                }-->
<!--                loss_stop()-->
<!--              </script>-->
<!--            </td>-->
<!--            <td style="padding:20px;width:75%;vertical-align:middle">-->
<!--              <a href="https://drive.google.com/open?id=1xpZ0fL9h1y9RfcTyPgVkxUrF3VwdkBvq">-->
<!--                <papertitle>A General and Adaptive Robust Loss Function</papertitle>-->
<!--              </a>-->
<!--              <br>-->
<!--              <strong>Jonathan T. Barron</strong>-->
<!--              <br>-->
<!--              <em>CVPR</em>, 2019 &nbsp <font color="red"><strong>(Oral Presentation, Best Paper Award Finalist)</strong></font>-->
<!--              <br>-->
<!--              <a href="https://arxiv.org/abs/1701.03077">arxiv</a> /-->
<!--              <a href="https://drive.google.com/open?id=1HNveL7xSNh6Ss7sxLK8Mw2L1Fc-rRhL4">supplement</a> /-->
<!--              <a href="https://youtu.be/BmNKbnF69eY">video</a> /-->
<!--              <a href="https://www.youtube.com/watch?v=4IInDT_S0ow&t=37m22s">talk</a> / -->
<!--              <a href="https://drive.google.com/file/d/1GzRYRIfLHvNLT_QwjHoBjHkBbs3Nbf0x/view?usp=sharing">slides</a> / -->
<!--              code: <a href="https://github.com/google-research/google-research/tree/master/robust_loss">TF</a>, <a href="https://github.com/google-research/google-research/tree/master/robust_loss_jax">JAX</a>, <a href="https://github.com/jonbarron/robust_loss_pytorch">pytorch</a> /-->
<!--              <a href="data/BarronCVPR2019_reviews.txt">reviews</a> /-->
<!--              <a href="data/BarronCVPR2019.bib">bibtex</a>-->
<!--              <p></p>-->
<!--              <p>A single robust loss function is a superset of many other common robust loss functions, and allows training to automatically adapt the robustness of its own loss.</p>-->
<!--            </td>-->
<!--          </tr>-->



<!--          <tr>-->
<!--            <td style="padding:20px;width:25%;vertical-align:middle">-->
<!--              <img src="images/bd_promo.jpg" alt="blind-date" width="160" height="160">-->
<!--            </td>-->
<!--            <td width="75%" valign="middle">-->
<!--              <a href="https://drive.google.com/file/d/1PQjzKgFcrAesMIDJr-WDlCwuGUxZJZwO/view?usp=sharing">-->
<!--                <papertitle>Blind Date: Using Proper Motions to Determine the Ages of Historical Images</papertitle>-->
<!--              </a>-->
<!--              <br>-->
<!--              <strong>Jonathan T. Barron</strong>, <a href="http://cosmo.nyu.edu/hogg/">David W. Hogg</a>, <a href="http://www.astro.princeton.edu/~dstn/">Dustin Lang</a>, <a href="http://cs.nyu.edu/~roweis/">Sam Roweis</a>-->
<!--              <br>-->
<!--              <em>The Astronomical Journal</em>, 136, 2008-->
<!--              <p>Using the relative motions of stars we can accurately estimate the date of origin of historical astronomical images.</p>-->
<!--            </td>-->
<!--          </tr>-->

<!--          <tr>-->
<!--            <td style="padding:20px;width:25%;vertical-align:middle">-->
<!--              <img src="images/clean_promo.jpg" alt="clean-usnob" width="160" height="160">-->
<!--            </td>-->
<!--            <td width="75%" valign="middle">-->
<!--              <a href="https://drive.google.com/file/d/1YvRx-4hrZoCk-nl6OgVJZlHAqOiN5hWq/view?usp=sharing">-->
<!--                <papertitle>Cleaning the USNO-B Catalog Through Automatic Detection of Optical Artifacts</papertitle>-->
<!--              </a>-->
<!--              <br>-->
<!--              <strong>Jonathan T. Barron</strong>, <a href="http://stumm.ca/">Christopher Stumm</a>, <a href="http://cosmo.nyu.edu/hogg/">David W. Hogg</a>, <a href="http://www.astro.princeton.edu/~dstn/">Dustin Lang</a>, <a href="http://cs.nyu.edu/~roweis/">Sam Roweis</a>-->
<!--              <br>-->
<!--              <em>The Astronomical Journal</em>, 135, 2008-->
<!--              <p>We use computer vision techniques to identify and remove diffraction spikes and reflection halos in the USNO-B Catalog.</p>-->
<!--              <p>In use at <a href="http://www.astrometry.net">Astrometry.net</a></p>-->
<!--            </td>-->
<!--          </tr>-->

<!--        </tbody></table>-->

<!--				-->
<!--        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>-->
<!--          <tr>-->
<!--            <td>-->
<!--              <heading>Misc</heading>-->
<!--            </td>-->
<!--          </tr>-->
<!--        </tbody></table>-->
<!--        <table width="100%" align="center" border="0" cellpadding="20"><tbody>-->
<!--					-->
<!--          <tr>-->
<!--            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>-->
<!--            <td width="75%" valign="center">-->
<!--              <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>-->
<!--              <br>-->
<!--              <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Longuet-Higgins Award Committee Member, CVPR 2021</a>-->
<!--              <br>-->
<!--              <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>-->
<!--              <br>-->
<!--              <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>-->
<!--            </td>-->
<!--          </tr>-->
<!--          <tr>-->
<!--            <td style="padding:20px;width:25%;vertical-align:middle">-->
<!--              <img src="images/cs188.jpg" alt="cs188">-->
<!--            </td>-->
<!--            <td width="75%" valign="center">-->
<!--              <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>-->
<!--              <br>-->
<!--              <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>-->
<!--              <br>-->
<!--              <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>-->
<!--            </td>-->
<!--          </tr>-->
<!--					-->

<!--          <tr>-->
<!--            <td align="center" style="padding:20px;width:25%;vertical-align:middle">-->
<!--              <heading>Basically <br> Blog Posts</heading>-->
<!--            </td>-->
<!--            <td width="75%" valign="middle">-->
<!--              <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>-->
<!--              <br>-->
<!--              <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>-->
<!--              <br>-->
<!--              <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>-->
<!--            </td>-->
<!--          </tr>-->
<!--        </tbody></table>-->

<!--        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>-->
<!--          <tr>-->
<!--            <td style="padding:0px">-->
<!--              <br>-->
<!--              <p style="text-align:right;font-size:small;">-->
<!--                Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>,-->
<!--                just add a link back to my website.-->
<!--                <strong>Do not</strong> scrape the HTML from the deployed instance of this website at http://jonbarron.info,-->
<!--                as it includes analytics tags that you do not want on your own website &mdash; use the github code instead. If you'd like your new page linked to from here, submit a pull request adding yourself.-->
<!--                <br>-->
<!--              </p>-->
<!--            </td>-->
<!--          </tr>-->
<!--        </tbody></table>-->


<!--        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>-->
<!--            <tr>-->
<!--            <td style="padding:20px;width:100%;vertical-align:middle">-->
<!--              <heading>Industry Experience</heading>-->
<!--              <p>-->
<!--                I'm interested in computer vision, machine learning, optimization, and image processing. Much of my research is about inferring the physical world (shape, motion, color, light, etc) from images. Representative papers are <span class="highlight">highlighted</span>.-->
<!--              </p>-->
<!--            </td>-->
<!--          </tr>-->
<!--        </tbody></table>-->

<!--        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>-->
<!--            <tr>-->
<!--            <td style="padding:20px;width:100%;vertical-align:middle">-->
<!--              <heading>Research Experience</heading>-->
<!--              <p>-->
<!--                I'm interested in computer vision, machine learning, optimization, and image processing. Much of my research is about inferring the physical world (shape, motion, color, light, etc) from images. Representative papers are <span class="highlight">highlighted</span>.-->
<!--              </p>-->
<!--            </td>-->
<!--          </tr>-->
<!--        </tbody></table>-->


<!--        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>-->
<!--            <tr>-->
<!--            <td style="padding:20px;width:100%;vertical-align:middle">-->
<!--              <heading>Education</heading>-->
<!--              <p>-->
<!--                I'm interested in computer vision, machine learning, optimization, and image processing. Much of my research is about inferring the physical world (shape, motion, color, light, etc) from images. Representative papers are <span class="highlight">highlighted</span>.-->
<!--              </p>-->
<!--            </td>-->
<!--          </tr>-->
<!--        </tbody></table>-->


<!--        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>-->
<!--            <tr>-->
<!--            <td style="padding:20px;width:100%;vertical-align:middle">-->
<!--              <heading>Collaboration</heading>-->
<!--              <p>-->
<!--                I'm interested in computer vision, machine learning, optimization, and image processing. Much of my research is about inferring the physical world (shape, motion, color, light, etc) from images. Representative papers are <span class="highlight">highlighted</span>.-->
<!--              </p>-->
<!--            </td>-->
<!--          </tr>-->
<!--        </tbody></table>-->


      </td>
    </tr>

  </table>

<script type="text/javascript" id="mapmyvisitors" src="//mapmyvisitors.com/map.js?d=wtLsBpK15wiz4T_kDzoTj2Vzx04mxshM4i_egY8HUGs&cl=ffffff&w=a"></script>

</body>
</html>