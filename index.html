<!DOCTYPE HTML>
<html lang="en" xmlns="http://www.w3.org/1999/html">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Xuanbai Chen</title>
  <meta name="author" content="Xuanbai Chen">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>


<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">


        <!--bio paragraph-->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Xuanbai Chen</name>
              </p>
              <p>Xuanbai Chen is an Applied Scientist in <a href="https://aws.amazon.com/rekognition/">AWS AI Rekognition</a> team, and is currently
                working on face recognition and trustworthy AI.
              </p>
              <p>
                Prior to AWS, he obtained my <a href="https://www.ri.cmu.edu/education/academic-programs/master-of-science-computer-vision/">Master of Science in Computer Vision (MSCV)</a> Degree
                in the <a href="https://www.ri.cmu.edu/">Robotics Institute</a>, <a href="https://www.cs.cmu.edu/">School of Computer Science</a>, <a href="https://www.cmu.edu/">Carnegie Mellon University</a>.
                He worked with <a href="https://www.cs.cmu.edu/~ftorre/">Prof. Fernando De la Torre</a> on Fairness for Generation Model and 3D Face modeling.
                He obtained my Bachelor of Engineering in Computer Science Degree in <a href="https://cc.nankai.edu.cn/">College of Computer Science</a>, <a href="https://en.nankai.edu.cn/">Nankai University</a>, working on Video Summarization.
              </p>
              <p style="text-align:center">
                <a href="mailto:xuanbaic98@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/xuanbaic/">LinkedIn</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=UZ8IbowAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.overleaf.com/read/swvmmvvqfhqy">CV</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/xuanbaic.jpg"><img style="width:80%;max-width:80%" alt="profile photo" src="images/xuanbaic.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>News</heading>
            <p>
              <li style="margin: 5px;" >
                  <b>2023-10:</b> ITI-GEN has entered the <b>Best Paper Finalist</b> (17 of 2161, <b>Top 0.7%</b>) for ICCV 2023.
              </li>
              <li style="margin: 5px;" >
                  <b>2023-08:</b> Our <a href="https://czhang0528.github.io/iti-gen"> ITI-GEN</a> has been accepted by <a href="https://iccv2023.thecvf.com/">ICCV 2023</a> as an <b>Oral</b> paper.
              </li>
              <li style="margin: 5px;" >
                <b>2023-07:</b> I joined <a href="https://aws.amazon.com/rekognition/">AWS AI Rekognition</a> team as an Applied Scientist!
              </li>
<!--              <li style="margin: 5px;" >-->
<!--                <b>2021-09:</b> <a href="https://dynamicvit.ivg-research.xyz"> DynamicViT</a> is accepted to <a href="https://neurips.cc/Conferences/2021">NeurIPS 2021</a>.-->
<!--              </li>-->
<!--              <li style="margin: 5px;" >-->
<!--                <b>2021-07:</b> Two papers are accepted to <a href="https://iccv2021.thecvf.com">ICCV 2021</a>.-->
<!--              </li>-->
<!--              <li style="margin: 5px;" >-->
<!--                <b>2020-12:</b> One paper on image classification is accepted to <a href="https://aaai.org/Conferences/AAAI-21/">AAAI 2021</a>.-->
<!--              </li>-->
<!--              <li style="margin: 5px;" >-->
<!--                <b>2020-07:</b> One paper on knowledge distillation is accepted by <a href="https://eccv2020.eu/">ECCV 2020</a>.-->
<!--              </li>-->
            </p>
          </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading> (* indicates equal contribution)
            </td>
          </tr>
        </tbody></table>



        <!--   iti-gen     -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td align="center" valign="middle">&nbsp;&nbsp;&nbsp;<img src="images/iti_gen/teaser.png", width="200">&nbsp;&nbsp;&nbsp;&nbsp;
			</td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_ITI-GEN_Inclusive_Text-to-Image_Generation_ICCV_2023_paper.html">
                <span class="papertitle">ITI-GEN: Inclusive Text-to-Image Generation</span>
              </a>
              <br>
              <a href="https://czhang0528.github.io/">Cheng Zhang</a>,
              <strong>Xuanbai Chen</strong>,
              <a href="https://www.linkedin.com/in/siqi-chai/">Siqi Chai</a>,
              <a href="https://scholar.google.com/citations?hl=en&user=WFKit_4AAAAJ&view_op=list_works&sortby=pubdate">Chen Henry Wu</a>,
              <a href="https://www.linkedin.com/in/dmitry-lagun-738b1221/">Dmitry Lagun</a>,
              <a href="https://thabobeeler.com/">Thabo Beeler</a>,
              <a href="https://www.cs.cmu.edu/~ftorre/">Fernando De la Torre</a>
              <br>
              <em>ICCV</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation, Best Paper Finalist, Top 0.7%)</strong></font>
              <br>
              <a href="https://czhang0528.github.io/iti-gen">project page</a>
              /
              <a href="https://arxiv.org/abs/2309.05569">arXiv</a>
              /
              <a href="https://github.com/humansensinglab/ITI-GEN">code</a>
              /
              <a href="https://drive.google.com/drive/folders/1_vwgrcSq6DKm5FegICwQ9MwCA63SkRcr?usp=sharing">data</a>
              /
              <a href="images/iti_gen/iti-gen_poster.pdf">poster</a>
              <p></p>
              <p>
              Debias the text-to-image generation model and implement the inclusiveness.
              </p>
            </td>
          </tr>
        </tbody></table>


        <!--   3d face cam     -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td align="center" valign="middle">&nbsp;&nbsp;&nbsp;<img src="images/3dfacecam/3dfacecam.gif", width="200">&nbsp;&nbsp;&nbsp;&nbsp;
			</td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content/WACV2023/html/Taherkhani_Controllable_3D_Generative_Adversarial_Face_Model_via_Disentangling_Shape_and_WACV_2023_paper.html">
                <span class="papertitle">Controllable 3D Generative Adversarial Face Model via Disentangling Shape and Appearance</span>
              </a>
              <br>
              <a href="https://ulteraa.github.io/Fariborz.github.io/">Fariborz Taherkhani</a>,
              <a href="https://aashishrai3799.github.io/">Aashish Rai</a>,
              <a href="https://zerg-overmind.github.io/">Quankai Gao</a>,
              <a href="https://shaunak99.github.io/profilev2/">Shaunak Srivastava</a>,
              <strong>Xuanbai Chen</strong>,
              <a href="https://www.cs.cmu.edu/~ftorre/">Fernando De la Torre</a>,
              Steven Song,
              <a href="https://aayushp.github.io/">Aayush Prakash</a>,
              Daeil Kim
              <br>
              <em>WACV</em>, 2023
              <br>
              <a href="https://aashishrai3799.github.io/3DFaceCAM/">project page</a>
              /
              <a href="https://arxiv.org/abs/2208.14263">arXiv</a>
              /
              <a href="https://github.com/aashishrai3799/3DFaceCAM/tree/main#controllable-3d-generative-adversarial-face-model-via-disentangling-shape-and-appearance">code</a>
              /
              <a href="https://drive.google.com/file/d/1PqIN4Rzp4vapWs2pUegUEoMhg4lM2Smy/view">video</a>
              <p></p>
              <p>
              A new 3D face generative model that can decouple identity and expression and provides granular control over expressions.
              </p>
            </td>
          </tr>
        </tbody></table>



        <!--   KAMV    -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td align="center" valign="middle">&nbsp;&nbsp;&nbsp;<img src="images/kamv/figure.png", width="140">&nbsp;&nbsp;&nbsp;&nbsp;
			</td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://dl.acm.org/doi/abs/10.1145/3503161.3548089">
                <span class="papertitle">A Knowledge Augmented and Multimodal-Based Framework for Video Summarization</span>
              </a>
              <br>
              <a href="https://www.semanticscholar.org/author/Jiehang-Xie/147178951">Jiehang Xie*</a>,
              <strong>Xuanbai Chen*</strong>,
              <a href="https://www.shaopinglu.net/">Shao-Ping Lu</a>,
              <a href="https://dblp.org/pid/14/1508.html">Yulu Yang</a>
              <br>
              <em>ACMMM</em>, 2022
              <br>
              <a href="https://dl.acm.org/doi/abs/10.1145/3503161.3548089">project page</a>
              /
              <a href="https://dl.acm.org/doi/pdf/10.1145/3503161.3548089">pdf</a>
              /
              <a href="https://dl.acm.org/action/downloadSupplement?doi=10.1145%2F3503161.3548089&file=MM22-1409.mp4">video</a>
              <p></p>
              <p>
              Propose a knowledge augmented and multimodal-based video summarization method.
              </p>
            </td>
          </tr>
        </tbody></table>





    </td></tr>
  </tbody></table>

    <p>
      <center>
          <div id="clustrmaps-widget" style="width:20%">
            <script type="text/javascript" id="mapmyvisitors" src="//mapmyvisitors.com/map.js?d=_4wnmcZthdDL7Y20ecaEP9y8aJ2WGqD1dpAjBwIP6uU&cl=ffffff&w=a"></script>
          </div>
          <br>&copy; Xuanbai Chen | Last updated: Oct 4, 2023
      </center>
    </p>
  </body>
</html>